{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802cf3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "BASE_TEST_DIR = 'results/reports'\n",
    "OUTPUT_DIR = 'results/graphs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba32622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_log_file(filepath):\n",
    "    \"\"\"\n",
    "    Parses a single log file according to the AEAgle standard.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"File not found: {filepath}\")\n",
    "        return None\n",
    "\n",
    "    tick_hz = 1\n",
    "    data = defaultdict(list)\n",
    "\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(',')\n",
    "            if not parts or not parts[0]: continue\n",
    "            keyword = parts[0]\n",
    "            \n",
    "            try:\n",
    "                if keyword == \"META\" and parts[1] == \"tick_hz\":\n",
    "                    tick_hz = int(parts[2])\n",
    "                elif keyword == \"TIME\":\n",
    "                    record = {\n",
    "                        'phase': parts[1], 'operation': parts[2], 'size': int(parts[3]),\n",
    "                        't_in': int(parts[4]), 't_out': int(parts[5]),\n",
    "                        'duration_ticks': int(parts[5]) - int(parts[4]),\n",
    "                        'result': parts[6], 'alloc_cnt': int(parts[7]), 'free_cnt': int(parts[8]),\n",
    "                    }\n",
    "                    data['time'].append(record)\n",
    "                elif keyword == \"SNAP\":\n",
    "                    record = {\n",
    "                        'phase': parts[1], 'free_bytes': int(parts[2]),\n",
    "                        'allocated_bytes': int(parts[3]), 'max_allocated_bytes': int(parts[4]),\n",
    "                        'timestamp': data['time'][-1]['t_out'] if data['time'] else 0\n",
    "                    }\n",
    "                    data['snap'].append(record)\n",
    "                elif keyword == \"FAULT\":\n",
    "                    data['fault'].append({'tick': int(parts[1]), 'error_code': parts[3]})\n",
    "                elif keyword in [\"LEAK\", \"NOLEAK\"]:\n",
    "                    data['leak'].append({'result': keyword, 'address': parts[1]})\n",
    "            except (IndexError, ValueError) as e:\n",
    "                print(f\"Skipping malformed line in {filepath}: {line.strip()} -> Error: {e}\")\n",
    "\n",
    "    dfs = {}\n",
    "    for key, records in data.items():\n",
    "        df = pd.DataFrame(records)\n",
    "        if 'duration_ticks' in df.columns:\n",
    "            df['duration_us'] = (df['duration_ticks'] * 1000000.0 / tick_hz) if tick_hz else 0\n",
    "        if 'timestamp' in df.columns:\n",
    "            df['time_s'] = df['timestamp'] / tick_hz if tick_hz else 0\n",
    "        dfs[key] = df\n",
    "    dfs['meta'] = {'tick_hz': tick_hz}\n",
    "    return dfs\n",
    "\n",
    "def load_all_test_data(base_dir):\n",
    "    \"\"\"\n",
    "    Walks the test directory structure and organizes parsed data.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(base_dir):\n",
    "        print(f\"Error: Base directory '{base_dir}' not found.\")\n",
    "        return {}\n",
    "    all_data = defaultdict(dict)\n",
    "    print(f\"Searching for allocators in '{base_dir}'...\")\n",
    "    for allocator_name in sorted(os.listdir(base_dir)):\n",
    "        allocator_path = os.path.join(base_dir, allocator_name)\n",
    "        if os.path.isdir(allocator_path):\n",
    "            # print(f\"  Processing allocator: {allocator_name}\")\n",
    "            for filename in sorted(os.listdir(allocator_path)):\n",
    "                if filename.endswith(\".csv\"):\n",
    "                    test_name = os.path.splitext(filename)[0]\n",
    "                    log_path = os.path.join(allocator_path, filename)\n",
    "                    parsed_data = parse_log_file(log_path)\n",
    "                    if parsed_data:\n",
    "                        all_data[allocator_name][test_name] = parsed_data\n",
    "    return dict(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33bb7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_allocator_data = load_all_test_data(BASE_TEST_DIR)\n",
    "\n",
    "print(\"\\n--- Data Loading Complete ---\")\n",
    "if all_allocator_data:\n",
    "    print(\"The following data has been loaded and is ready for analysis:\")\n",
    "    for allocator, tests in all_allocator_data.items():\n",
    "        print(f\"  - {allocator}: {list(tests.keys())}\")\n",
    "else:\n",
    "    print(\"No data was loaded. Please check your directory structure and .csv files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845dc4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucket_time_data(df, bucket_size, tick_hz):\n",
    "    \"\"\"Transforms a DataFrame of TIME logs into bucketed data.\"\"\"\n",
    "    if df.empty or tick_hz == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    num_buckets = len(df) // bucket_size\n",
    "    if num_buckets == 0:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    reshaped_df = df.iloc[:num_buckets * bucket_size].copy()\n",
    "    reshaped_df['bucket'] = np.repeat(np.arange(num_buckets), bucket_size)\n",
    "\n",
    "    bucketed = reshaped_df.groupby('bucket').agg(\n",
    "        t_in_first=('t_in', 'first'),\n",
    "        t_out_last=('t_out', 'last'),\n",
    "    )\n",
    "    \n",
    "    bucketed['total_duration_ticks'] = bucketed['t_out_last'] - bucketed['t_in_first']\n",
    "    bucketed['avg_duration_ticks'] = bucketed['total_duration_ticks'] / bucket_size\n",
    "    bucketed['avg_duration_us'] = (bucketed['avg_duration_ticks'] * 1000000.0) / tick_hz\n",
    "    \n",
    "    return bucketed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72010aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_save_grid(plot_data_list, figure_title, filename, output_dir, bucket_size, plot_unit='ticks', outlier_k=3.0):\n",
    "    \"\"\"\n",
    "    Creates and saves a grid of plots with corrected conditional outlier filtering.\n",
    "    \"\"\"\n",
    "    if not plot_data_list:\n",
    "        print(f\"No data to plot for '{figure_title}'.\")\n",
    "        return\n",
    "    \n",
    "    y_column, y_label = ('avg_duration_us', 'Avg Latency per Op (Âµs)') if plot_unit == 'us' else ('avg_duration_ticks', 'Avg Latency per Op (Ticks)')\n",
    "\n",
    "    nrows, ncols = 4, 3\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(12, 8), constrained_layout=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, plot_info in enumerate(plot_data_list):\n",
    "        if i >= len(axes): break\n",
    "        ax = axes[i]\n",
    "        df = plot_info['data']\n",
    "        allocator = plot_info['allocator']\n",
    "        \n",
    "        plot_df = df\n",
    "\n",
    "        if allocator.startswith('freertos'):\n",
    "            ABSOLUTE_THRESHOLD_US = 30000.0\n",
    "            tick_hz = plot_info['tick_hz']\n",
    "            \n",
    "            if plot_unit == 'us':\n",
    "                absolute_threshold = ABSOLUTE_THRESHOLD_US\n",
    "            else: # unit is 'ticks'\n",
    "                absolute_threshold = (ABSOLUTE_THRESHOLD_US * tick_hz) / 1000000.0\n",
    "\n",
    "            # Pass 1: Filter using the absolute threshold\n",
    "            extreme_outliers = df[df[y_column] > absolute_threshold]\n",
    "            sane_df = df[df[y_column] <= absolute_threshold]\n",
    "            \n",
    "            # if not extreme_outliers.empty:\n",
    "            #     print(f\"\\n*** Pass 1: Extreme Outlier Omitted for {allocator} ({plot_info['test_name']}) ***\")\n",
    "            #     print(f\"    (Absolute Threshold > {absolute_threshold:.2f} {plot_unit})\")\n",
    "            #     print(extreme_outliers[['avg_duration_ticks', 'avg_duration_us']])\n",
    "            \n",
    "            q1 = sane_df[y_column].quantile(0.25)\n",
    "            q3 = sane_df[y_column].quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            \n",
    "            if iqr > 0:\n",
    "                statistical_threshold = q3 + (iqr * outlier_k)\n",
    "                statistical_outliers = sane_df[sane_df[y_column] > statistical_threshold]\n",
    "                # if not statistical_outliers.empty:\n",
    "                #     print(f\"\\n--- Pass 2: Statistical Outlier Omitted for {allocator} ({plot_info['test_name']}) ---\")\n",
    "                #     print(f\"    (Statistical Threshold > {statistical_threshold:.2f} {plot_unit})\")\n",
    "                #     print(statistical_outliers[['avg_duration_ticks', 'avg_duration_us']])\n",
    "                plot_df = sane_df[sane_df[y_column] <= statistical_threshold]\n",
    "            else:\n",
    "                plot_df = sane_df\n",
    "\n",
    "        ax.plot(plot_df.index, plot_df[y_column], marker='.', linestyle='-', markersize=4)\n",
    "        ax.set_title(allocator, fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel(f'Bucket Index (Size = {bucket_size})', fontsize=10)\n",
    "        ax.set_ylabel(y_label, fontsize=10)\n",
    "        ax.grid(True, which=\"both\", ls=\"--\", linewidth=0.5)\n",
    "\n",
    "    for i in range(len(plot_data_list), len(axes)):\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    fig.suptitle(figure_title, fontsize=22, fontweight='bold')\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    plt.savefig(output_path, format='pdf', bbox_inches='tight')\n",
    "    print(f\"\\n  - Saved grid plot to {output_path}\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a92e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bucketed_latency(all_data, output_dir, bucket_size=2, unit='ticks'):\n",
    "    \"\"\"\n",
    "    Main function to process and plot bucketed latency data for all allocators.\n",
    "    This function calls the helper 'create_and_save_grid' to do the plotting.\n",
    "\n",
    "    Args:\n",
    "        all_data (dict): The fully loaded dictionary of allocator data.\n",
    "        output_dir (str): The directory to save plots into.\n",
    "        bucket_size (int): The number of operations to group into a bucket.\n",
    "        unit (str): The unit for the y-axis. Can be 'ticks' or 'us'.\n",
    "    \"\"\"\n",
    "    # Define a constant for outlier sensitivity\n",
    "    OUTLIER_K = 3.0\n",
    "    \n",
    "    if unit not in ['ticks', 'us']:\n",
    "        print(f\"Invalid unit '{unit}'. Please choose 'ticks' or 'us'.\")\n",
    "        return\n",
    "\n",
    "    \n",
    "    # --- Step 1: Data Segregation and Bucketing ---\n",
    "    mixed_lifetime_plots = []\n",
    "    leak_exhaust_plots = []\n",
    "    \n",
    "    ordered_allocators = [\n",
    "    'contiki-heapmem',\n",
    "    'freertosv1',\n",
    "    'newlib',\n",
    "    'contiki-memb',\n",
    "    'freertosv2',\n",
    "    'newlib-nano',\n",
    "    'riot-mema',\n",
    "    'freertosv4',\n",
    "    'zephyr',\n",
    "    'riot-tlsf'\n",
    "]\n",
    "    \n",
    "    mixed_lifetime_plots = []\n",
    "    leak_exhaust_plots = []\n",
    "\n",
    "\n",
    "    for allocator in ordered_allocators:\n",
    "        if allocator in all_data:\n",
    "            tests = all_data[allocator]\n",
    "\n",
    "            # Prepare MixedLifetime data\n",
    "            if 'MixedLifetime' in tests and 'time' in tests['MixedLifetime']:\n",
    "                tick_hz = tests['MixedLifetime']['meta'].get('tick_hz', 1)\n",
    "                burst_df = tests['MixedLifetime']['time'][lambda x: x['phase'] == 'burst']\n",
    "                bucketed_data = bucket_time_data(burst_df, bucket_size, tick_hz)\n",
    "                if not bucketed_data.empty:\n",
    "                    mixed_lifetime_plots.append({\n",
    "                        'allocator': allocator,\n",
    "                        'test_name': 'MixedLifetime',\n",
    "                        'data': bucketed_data,\n",
    "                        'tick_hz': tick_hz\n",
    "                    })\n",
    "\n",
    "            # Prepare LeakExhaust data\n",
    "            if 'LeakExhaust' in tests and 'time' in tests['LeakExhaust']:\n",
    "                tick_hz = tests['LeakExhaust']['meta'].get('tick_hz', 1)\n",
    "                leak_loop_df = tests['LeakExhaust']['time'][lambda x: x['phase'] == 'leakloop']\n",
    "                bucketed_data = bucket_time_data(leak_loop_df, bucket_size, tick_hz)\n",
    "                if not bucketed_data.empty:\n",
    "                    leak_exhaust_plots.append({\n",
    "                        'allocator': allocator,\n",
    "                        'test_name': 'LeakExhaust',\n",
    "                        'data': bucketed_data,\n",
    "                        'tick_hz': tick_hz\n",
    "                    })\n",
    "\n",
    "    # --- Step 2: Call the plotting grid function for each test type ---\n",
    "    unit_suffix = unit.capitalize()\n",
    "    mixed_filename = f\"Bucketed_Latency_MixedLifetime_B{bucket_size}_{unit_suffix}_Filtered.pdf\"\n",
    "    leak_filename = f\"Bucketed_Latency_LeakExhaust_B{bucket_size}_{unit_suffix}_Filtered.pdf\"\n",
    "    \n",
    "    create_and_save_grid(mixed_lifetime_plots, \n",
    "                         f'Avg Latency in Buckets of {bucket_size}: Mixed Lifetime (Burst)', \n",
    "                         mixed_filename, \n",
    "                         output_dir,\n",
    "                         bucket_size=bucket_size,\n",
    "                         plot_unit=unit,\n",
    "                         outlier_k=OUTLIER_K)\n",
    "\n",
    "    create_and_save_grid(leak_exhaust_plots, \n",
    "                         f'Avg Malloc Latency in Buckets of {bucket_size}: Leak & Exhaust', \n",
    "                         leak_filename, \n",
    "                         output_dir,\n",
    "                         bucket_size=bucket_size,\n",
    "                         plot_unit=unit,\n",
    "                         outlier_k=OUTLIER_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195cd39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bucketed_latency(all_allocator_data, OUTPUT_DIR, 2, \"us\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c19436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_volumetric_efficiency(all_data, output_dir):\n",
    "    \"\"\"\n",
    "    Generates a bar chart comparing the maximum bytes each allocator was able\n",
    "    to serve before exhaustion. Includes a reference line for theoretical max\n",
    "    heap size and has fallback logic for missing final snapshots.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Generating Modified Volumetric Efficiency Plot (Metric 4) ---\")\n",
    "    \n",
    "    efficiency_data = []\n",
    "    for allocator, tests in all_data.items():\n",
    "        if 'LeakExhaust' in tests and 'snap' in tests['LeakExhaust']:\n",
    "            snap_df = tests['LeakExhaust']['snap']\n",
    "            if snap_df.empty:\n",
    "                print(f\"  - Warning: No snapshot data found for {allocator}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            final_snap = snap_df[snap_df['phase'] == 'after_leakloop_exhaustion']\n",
    "            \n",
    "            #If the specific final snapshot isn't found, use the last available one\n",
    "            if final_snap.empty:\n",
    "                final_snap = snap_df.tail(1)\n",
    "                print(f\"  - Note: Using last available snapshot for {allocator} (phase: '{final_snap['phase'].iloc[0]}').\")\n",
    "\n",
    "            max_bytes = final_snap['max_allocated_bytes'].iloc[0]\n",
    "            efficiency_data.append({\n",
    "                'allocator': allocator,\n",
    "                'max_allocated_bytes': max_bytes\n",
    "            })\n",
    "\n",
    "    if not efficiency_data:\n",
    "        print(\"No LeakExhaust snapshot data found to generate efficiency plot.\")\n",
    "        return\n",
    "\n",
    "    efficiency_df = pd.DataFrame(efficiency_data)\n",
    "    efficiency_df.sort_values('max_allocated_bytes', ascending=False, inplace=True)\n",
    "\n",
    "    plt.figure(figsize=(10,7))\n",
    "    bar_plot = sns.barplot(\n",
    "        x='max_allocated_bytes',\n",
    "        y='allocator',\n",
    "        data=efficiency_df,\n",
    "        palette='magma',\n",
    "        hue='allocator',\n",
    "        legend=False,\n",
    "        orient='h'\n",
    "    )\n",
    "\n",
    "    plt.title('Volumetric Efficiency: Max Bytes Allocated Before Exhaustion', fontsize=20, fontweight='bold')\n",
    "    plt.xlabel('Max Allocated Bytes (More is Better)', fontsize=12)\n",
    "    plt.ylabel('Allocator', fontsize=12)\n",
    "    plt.grid(axis='x', linestyle='--', linewidth=0.6)\n",
    "    \n",
    "    plt.axvline(x=65536, color='r', linestyle='--', linewidth=2, label='Theoretical Max Heap (65536 bytes)')\n",
    "    plt.legend()\n",
    "    \n",
    "    for container in bar_plot.containers:\n",
    "        bar_plot.bar_label(container, fmt='{:,.0f}', padding=5)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "\n",
    "    filename = \"Volumetric_Efficiency_Comparison_Modified.pdf\"\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    plt.savefig(output_path, format='pdf')\n",
    "    print(f\"  - Saved modified volumetric efficiency plot to {output_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904067dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_volumetric_efficiency(all_allocator_data, OUTPUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
